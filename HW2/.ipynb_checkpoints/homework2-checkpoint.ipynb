{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546432bb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dataset and preprocessing\n",
    "我们用的数据集是来自medium.com的文章，共有190000多篇，内容包括科技、社会、健康、环境保护和生活方式等主题，我们取其中的100篇作为这次实验的数据集。这个数据集为一个csv文件，每一行包括文章标题、文章文本、文章url、作者、发布时间和文章的标签等。在这次实验中，我们只使用到文章的文本。\n",
    "\n",
    "在预处理部分，我们要把文本中的标点符号、数字、特殊符号等去掉，然后将文本中的单词转换为小写，并且将文本中的单词分割为一个一个的词语。sklearn中的CountVectorizer类可以帮助我们实现这个功能。接下来我们要构建文本的空间向量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "845149ce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "\n",
    "# path = 'data'\n",
    "# files = []\n",
    "\n",
    "\n",
    "def get_text_list():\n",
    "    df = pd.read_csv('1.csv', nrows=265, encoding='utf-8')\n",
    "#     files = files = df['title'].values.tolist()\n",
    "#     print(df[['title', 'text', 'url', 'timestamp']].values.tolist())\n",
    "    return df['text'].values.tolist()\n",
    "\n",
    "\n",
    "def get_bag(texts):\n",
    "    bag = CountVectorizer(token_pattern='\\\\b[A-Za-z]+\\\\b')\n",
    "    count = bag.fit_transform(texts)\n",
    "    return bag, count\n",
    "\n",
    "\n",
    "def generate_inverse_index(text_list, bag, array):\n",
    "    result = defaultdict(list)\n",
    "    words = bag.get_feature_names_out()\n",
    "    for index, value in enumerate(text_list):\n",
    "        for i, word in enumerate(words):\n",
    "            if array[index][i] != 0:\n",
    "                position_list = [m.span() for m in re.finditer(\n",
    "                    r'\\b' + word + r'\\b', value)]\n",
    "                result[word].append((index, array[index][i], position_list))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4453737",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Get scores and search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8ef5022",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import math\n",
    "\n",
    "\n",
    "class ResultItem:\n",
    "    def __init__(self, index, title, text, url, timestamp):\n",
    "        self.index = index\n",
    "        self.title = title\n",
    "        self.text = text\n",
    "        self.url = url\n",
    "        self.timestamp = timestamp\n",
    "        self.rank = 0.0\n",
    "        self.freq = 0\n",
    "        self.count = 0\n",
    "        self.occurrence = []\n",
    "        self.similarity = 0.0\n",
    "\n",
    "    def __str__(self):\n",
    "        s = \"file_index: \" + str(self.index) + \\\n",
    "            \"\\ntitle: \" + self.title + \\\n",
    "            \"\\nurl: \" + self.url + \\\n",
    "            \"\\ntimestamp: \" + self.timestamp + \\\n",
    "            \"\\nfreq: \" + str(self.freq) + \\\n",
    "            \"\\nrank: \" + str(self.rank) + \\\n",
    "            \"\\nsimilarity: \" + str(self.similarity) + \\\n",
    "            \"\\n\"\n",
    "        for j in self.occurrence:\n",
    "            s += \"> ...\" + self.text[max(0, j[0] - 50):j[0] + 50] + \"...\\n\"\n",
    "        return s\n",
    "\n",
    "\n",
    "def get_similarity(a, b):\n",
    "    dot = 0\n",
    "    len_a = 0\n",
    "    len_b = 0\n",
    "    for i in range(len(a)):\n",
    "        dot += a[i] * b[i]\n",
    "        len_a += a[i] * a[i]\n",
    "        len_b += b[i] * b[i]\n",
    "    len_a = math.sqrt(len_a)\n",
    "    len_b = math.sqrt(len_b)\n",
    "    return dot / (len_a * len_b)\n",
    "\n",
    "\n",
    "def run_search(search_str, inverse_index, metadata, texts, bag, array):\n",
    "    temp = []\n",
    "    freq = []\n",
    "    s_list = search_str.split(' ')\n",
    "    for s in s_list:\n",
    "        temp.append(inverse_index[s].copy())\n",
    "        freq.append(0)\n",
    "        if inverse_index[s]:\n",
    "            for i in inverse_index[s]:\n",
    "                freq[-1] += i[1]\n",
    "    result_dict = {}\n",
    "    for index, i in enumerate(temp):\n",
    "        if not i:\n",
    "            continue\n",
    "        for j in i:\n",
    "            if j[0] not in result_dict:\n",
    "                item = ResultItem(j[0], metadata[j[0]][0], texts[j[0]], metadata[j[0]][1], metadata[j[0]][2])\n",
    "                item.count += 1\n",
    "                item.freq += j[1]\n",
    "                item.rank += j[1] * 100 / freq[index]\n",
    "                item.occurrence.extend(j[2])\n",
    "                result_dict[j[0]] = item\n",
    "            else:\n",
    "                result_dict[j[0]].count += 1\n",
    "                result_dict[j[0]].freq += j[1]\n",
    "                result_dict[j[0]].rank += j[1] * 100 / freq[index]\n",
    "                result_dict[j[0]].occurrence.extend(j[2])\n",
    "    result_list = [i for i in result_dict.values()]\n",
    "\n",
    "    search_vec = CountVectorizer(vocabulary=bag.get_feature_names_out()).fit_transform([search_str]).toarray()\n",
    "    for i in result_list:\n",
    "        i.similarity = get_similarity(search_vec[0], array[i.index].A[0])\n",
    "\n",
    "    result_list.sort(key=lambda x: -x.rank * x.count)\n",
    "    return result_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "923f82df",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bye :)\n"
     ]
    }
   ],
   "source": [
    "import IPython.display as display\n",
    "print(\"Loading data...\")\n",
    "text_list = get_text_list()\n",
    "print(\"Vectorizing...\")\n",
    "bag, count = get_bag(text_list)\n",
    "print(\"Generating index...\")\n",
    "inverse_index = generate_inverse_index(text_list, bag, count.toarray())\n",
    "print(\"Done.\")\n",
    "df = pd.read_csv('1.csv', nrows=265, encoding='utf-8')\n",
    "metadata = df[['title', 'url', 'timestamp']].values.tolist()\n",
    "while True:\n",
    "    search_str = input(\"Type your keyword to search now. Type q to exit.\\n> \")\n",
    "    display.clear_output()\n",
    "    if search_str == 'q':\n",
    "        print('Bye :)')\n",
    "        break\n",
    "    \n",
    "    result = run_search(search_str, inverse_index, metadata, text_list, bag, count)\n",
    "    for i in result:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935b48ac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
