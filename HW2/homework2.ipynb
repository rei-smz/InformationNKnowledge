{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546432bb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dataset and preprocessing\n",
    "我们用的数据集是来自medium.com的文章，共有190000多篇，内容包括科技、社会、健康、环境保护和生活方式等主题，我们取其中的100篇作为这次实验的数据集。这个数据集为一个csv文件，每一行包括文章标题、文章文本、文章url、作者、发布时间和文章的标签等。在这次实验中，我们只使用到文章的文本。\n",
    "\n",
    "在预处理部分，我们要把文本中的标点符号、数字、特殊符号等去掉，然后将文本中的单词转换为小写，并且将文本中的单词分割为一个一个的词语。sklearn中的CountVectorizer类可以帮助我们实现这个功能。除此之外，我们还设置了一个停用词表，排除一些对理解文章主要内容没有帮助的词语，这样可以提高计算的效率。接下来我们要构建文本的空间向量，在本实验中为了方便我们直接使用词袋来实现这项功能，也就是说我们只考虑每个单词在每篇文章中的词频，而不考虑文章的结构、单词出现的位置等信息。在下面的代码中，我们使用CountVectorizer类的fit_transform方法来构建文本的空间向量，count[i][j]表示的是第j个单词在第i个文本中出现的次数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "845149ce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "\n",
    "FILE_CNT = 256\n",
    "STOP_WORDS = open('stopwords.txt', 'r', encoding='utf-8').read().split('\\n')\n",
    "\n",
    "def get_text_list():\n",
    "    df = pd.read_csv('1.csv', nrows=FILE_CNT, encoding='utf-8')\n",
    "    return df['text'].values.tolist()\n",
    "\n",
    "\n",
    "def get_bag(texts):\n",
    "    bag = CountVectorizer(token_pattern='\\\\b[A-Za-z]+\\\\b', stop_words=STOP_WORDS)\n",
    "    count = bag.fit_transform(texts)\n",
    "    return bag, count\n",
    "\n",
    "\n",
    "def generate_inverse_index(text_list, bag, array):\n",
    "    result = defaultdict(list)\n",
    "    words = bag.get_feature_names_out()\n",
    "    for index, value in enumerate(text_list):\n",
    "        for i, word in enumerate(words):\n",
    "            if array[index][i] != 0:\n",
    "                position_list = [m.span() for m in re.finditer(r'\\b' + word + r'\\b', value)]\n",
    "                result[word].append((index, array[index][i], position_list)) # 文章编号，词频，位置列表\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4453737",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Get scores and search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8ef5022",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import math\n",
    "\n",
    "\n",
    "def get_similarity(a, b):\n",
    "    dot = 0\n",
    "    len_a = 0\n",
    "    len_b = 0\n",
    "    for i in range(len(a)):\n",
    "        dot += a[i] * b[i]\n",
    "        len_a += a[i] * a[i]\n",
    "        len_b += b[i] * b[i]\n",
    "    len_a = math.sqrt(len_a)\n",
    "    len_b = math.sqrt(len_b)\n",
    "    return dot / (len_a * len_b)\n",
    "\n",
    "def get_tfidf_score(freq_of_text, word_cnt_of_text, text_cnt_of_word):\n",
    "    tf = freq_of_text / word_cnt_of_text\n",
    "    idf = math.log(FILE_CNT / (text_cnt_of_word + 1))\n",
    "    return tf * idf\n",
    "\n",
    "class ResultItem:\n",
    "    def __init__(self, index, title, text, url, timestamp):\n",
    "        self.index = index\n",
    "        self.title = title\n",
    "        self.text = text\n",
    "        self.url = url\n",
    "        self.timestamp = timestamp\n",
    "        self.score = 0.0\n",
    "        self.freq = 0\n",
    "        self.count = 0\n",
    "        self.occurrence = []\n",
    "        self.similarity = 0.0\n",
    "\n",
    "    def __str__(self):\n",
    "        s = \"file_index: \" + str(self.index) + \\\n",
    "            \"\\ntitle: \" + self.title + \\\n",
    "            \"\\nurl: \" + self.url + \\\n",
    "            \"\\ntimestamp: \" + self.timestamp + \\\n",
    "            \"\\nfreq: \" + str(self.freq) + \\\n",
    "            \"\\nscore: \" + str(self.score) + \\\n",
    "            \"\\nsimilarity: \" + str(self.similarity) + \\\n",
    "            \"\\n\"\n",
    "        for j in self.occurrence:\n",
    "            s += \"> ...\" + self.text[max(0, j[0] - 50):j[0] + 50] + \"...\\n\"\n",
    "        return s\n",
    "\n",
    "def run_search(search_str, inverse_index, metadata, texts, bag, array):\n",
    "    words_inverse_index = [] # 搜索单词的倒排索引\n",
    "    text_cnt = []\n",
    "    s_list = search_str.split(' ')\n",
    "    word_cnt = array.toarray().sum(axis=1)\n",
    "    for word in s_list:\n",
    "        words_inverse_index.append(inverse_index[word].copy())\n",
    "        text_cnt.append(0)\n",
    "        if inverse_index[word]:\n",
    "            text_cnt[-1] += len(inverse_index[word])\n",
    "    result_dict = {}\n",
    "    for index, inverse_index_item in enumerate(words_inverse_index):\n",
    "        if not inverse_index_item:\n",
    "            continue\n",
    "        for text_inverse_info in inverse_index_item:\n",
    "            text_index = text_inverse_info[0]\n",
    "            text_freq = text_inverse_info[1]\n",
    "            if text_index not in result_dict:\n",
    "                item = ResultItem(\n",
    "                    text_index,\n",
    "                    metadata[text_index][0],\n",
    "                    texts[text_index],\n",
    "                    metadata[text_index][1],\n",
    "                    metadata[text_index][2])\n",
    "                item.count += 1\n",
    "                item.freq += text_freq\n",
    "                item.score += get_tfidf_score(text_freq, word_cnt[text_index], text_cnt[index])\n",
    "                item.occurrence.extend(text_inverse_info[2])\n",
    "                result_dict[text_index] = item\n",
    "            else:\n",
    "                result_dict[text_index].count += 1\n",
    "                result_dict[text_index].freq += text_freq\n",
    "                result_dict[text_index].score += get_tfidf_score(text_freq, word_cnt[text_index], text_cnt[index])\n",
    "                result_dict[text_index].occurrence.extend(text_inverse_info[2])\n",
    "    result_list = [i for i in result_dict.values()]\n",
    "\n",
    "    search_vec = CountVectorizer(vocabulary=bag.get_feature_names_out()).fit_transform([search_str]).toarray()\n",
    "    for i in result_list:\n",
    "        i.similarity = get_similarity(search_vec[0], array[i.index].A[0])\n",
    "\n",
    "    result_list.sort(key=lambda x: -x.score * x.count)\n",
    "    return result_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Manual evaluation\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_manual_accuracy(total_search, fine_search):\n",
    "    if total_search == 0:\n",
    "        return float('nan')\n",
    "    return fine_search / total_search * 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923f82df",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_index: 190\n",
      "title: How can atmospheric pollution result to excessive harm in the marine ecosystems?\n",
      "url: https://medium.com/datadriveninvestor/how-atmospheric-pollution-can-result-to-excessive-harm-in-the-marine-ecosystems-922fc295a258\n",
      "timestamp: 2020-12-28 12:42:46.667000+00:00\n",
      "freq: 4\n",
      "score: 0.015267305600951218\n",
      "similarity: 0.030442246621763137\n",
      "> ...How can atmospheric pollution result to excessive harm in the marine e...\n",
      "> ...the atmospheric system, the focus is based on the pollution and the effect of the excessive quantiti...\n",
      "> ...ware of the fact that our harmful actions for the pollution of the air are equally and sometimes eve...\n",
      "> ...negative mechanism which is caused by atmospheric pollution and it’s attached to the acidic characte...\n",
      "\n",
      "file_index: 178\n",
      "title: There is Plastic in Your Fruits & Vegetables\n",
      "url: https://medium.com/age-of-awareness/there-is-plastic-in-your-fruits-vegetables-100ac353ac51\n",
      "timestamp: 2020-07-08 11:23:47.512000+00:00\n",
      "freq: 1\n",
      "score: 0.011318450614541665\n",
      "similarity: 0.023137240669137377\n",
      "> ...to vegetables.\n",
      "\n",
      "Apples show the highest amount of pollution for fruits and carrots for vegetables. T...\n",
      "\n",
      "file_index: 53\n",
      "title: The Sustainable Element-Technology Nexus that has Great Potential\n",
      "url: https://medium.com/climate-conscious/the-sustainable-element-technology-nexus-that-has-great-potential-30e46a8234a1\n",
      "timestamp: 2020-10-12 19:22:43.079000+00:00\n",
      "freq: 1\n",
      "score: 0.008429197413171543\n",
      "similarity: 0.019422053054479065\n",
      "> ...l\n",
      "\n",
      "A simple and cheap technique to mitigate water pollution\n",
      "\n",
      "The image is taken from the author’s ph...\n",
      "\n",
      "file_index: 123\n",
      "title: Being Well Pub Launches Medika to Expand Our Writers’ Reach\n",
      "url: https://medium.com/beingwell/being-well-pub-launches-medika-to-expand-our-writers-reach-40852aa25bcf\n",
      "timestamp: 2020-10-11 13:55:17.841000+00:00\n",
      "freq: 1\n",
      "score: 0.006544122355316817\n",
      "similarity: 0.0188914778984526\n",
      "> ...the developing research linking early exposure to pollution and Alzheimer’s disease.\n",
      "\n",
      "Society\n",
      "\n",
      "Sarah...\n",
      "\n",
      "file_index: 79\n",
      "title: Ecosystem restoration, reviving hope.\n",
      "url: https://medium.com/environmental-intelligence/ecosystem-restoration-reviving-hope-3dd8f7fc082f\n",
      "timestamp: 2019-06-17 08:39:15.804000+00:00\n",
      "freq: 1\n",
      "score: 0.0037492367660669264\n",
      "similarity: 0.00924105494511958\n",
      "> ...is degraded through soil erosion, salinization or pollution, it loses its wildlife and its ecosystem...\n",
      "\n",
      "file_index: 134\n",
      "title: The Future is Now\n",
      "url: https://medium.com/predict/the-future-is-now-c9ec1115a8d9\n",
      "timestamp: 2020-12-23 13:12:27.815000+00:00\n",
      "freq: 2\n",
      "score: 0.00322514990629413\n",
      "similarity: 0.010090976621451742\n",
      "> ...two centuries, beginning with coal and reaching a pollution peak as the massive population of China ...\n",
      "> ...vernments don’t seem to be doing much to slow our pollution of the environment or protect us from fu...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import IPython.display as display\n",
    "print(\"Loading data...\")\n",
    "text_list = get_text_list()\n",
    "print(\"Vectorizing...\")\n",
    "bag, count = get_bag(text_list)\n",
    "print(\"Generating index...\")\n",
    "inverse_index = generate_inverse_index(text_list, bag, count.toarray())\n",
    "print(\"Done.\")\n",
    "metadata = pd.read_csv('1.csv', nrows=FILE_CNT, encoding='utf-8')[['title', 'url', 'timestamp']].values.tolist()\n",
    "search_cnt = 0\n",
    "fine_search_cnt = 0\n",
    "while True:\n",
    "    manual_accuracy = get_manual_accuracy(search_cnt, fine_search_cnt)\n",
    "    search_str = input(f\"Current manual accuracy: {manual_accuracy}.\\nType your keyword to search now. Type q to exit.\\n> \")\n",
    "    display.clear_output()\n",
    "    if search_str == 'q':\n",
    "        print('Bye :)')\n",
    "        break\n",
    "\n",
    "    search_cnt += 1\n",
    "    result = run_search(search_str, inverse_index, metadata, text_list, bag, count)\n",
    "    for i in result:\n",
    "        print(i)\n",
    "    search_evaluate = input(\"Is this result correct? (Y/n)\\n> \")\n",
    "    if search_evaluate != 'n' or search_evaluate !=  'N':\n",
    "        fine_search_cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935b48ac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}